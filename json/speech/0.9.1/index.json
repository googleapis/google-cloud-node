{"id":"speech","type":"class","name":"Speech","overview":"<p>\n  This class allows you interact with Cloud Speech API.\n</p>\n\n\n\n<p>\n  First, install <code>@google-cloud/speech</code> with npm:\n</p>\n\n<div hljs language=\"bash\">$ npm install --save @google-cloud/speech</div>\n\n<p>\n  If you are running your app on Google Compute Engine, you won't need to worry about supplying connection configuration options to <code>@google-cloud/speech</code>â€” we figure that out for you.\n</p>\n\n<p>\n  However, if you're running your app elsewhere, you will need to provide project details to authenticate API requests.\n</p>\n\n<h4>Google Cloud Platform</h4>\n<div hljs language=\"javascript\">\nvar speech = require('@google-cloud/speech')();\n</div>\n\n<h4>Elsewhere</h4>\n<div hljs language=\"javascript\">\nvar speech = require('@google-cloud/speech')({\n  projectId: 'grape-spaceship-123',\n  keyFilename: '/path/to/keyfile.json'\n});\n</div>\n\n<p>\n  The full set of options which can be passed to <code>@google-cloud/speech</code> are outlined in our <a href=\"#/docs/speech/0.9.1/guides/authentication\">Authentication guide</a>.\n</p>\n","description":"<p>To learn more about the Speech API, see the <a href=\"https://cloud.google.com/speech/docs/getting-started\">Getting Started guide</a>.</p>","source":"packages/speech/src/index.js","parent":null,"children":["speech/v1"],"methods":[{"id":"Speech","name":"Speech","type":"constructor","description":"<p>The <a href=\"https://cloud.google.com/speech/docs\">Cloud Speech API</a> enables easy integration of Google speech recognition technologies into developer applications. Send audio and receive a text transcription from the Cloud Speech API service.</p>","source":"packages/speech/src/index.js#L58","resources":[{"title":"Getting Started","link":"https://cloud.google.com/speech/docs/getting-started"},{"title":"Speech Best Practices","link":"https://cloud.google.com/speech/docs/best-practices"}],"examples":[],"params":[{"name":"options","description":"<ul> <li><a href=\"#/docs\">Configuration object</a>.</li> </ul> ","types":["object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"eventTypes","name":"eventTypes","type":"instance","description":"<p>The event types that the Speech API will return while processing a <a data-custom-type=\"speech\" data-method=\"createRecognizeStream\">speech#createRecognizeStream</a> request. You can track the progress of audio recognition by comparing the <code>data.eventType</code> property with these values.</p><ul> <li><code>Speech.eventTypes.ENDPOINTER_EVENT_UNSPECIFIED</code>: No event specified.</li> <li><code>Speech.eventTypes.END_OF_SINGLE_UTTERANCE</code>: This event is only sent when <code>config.singleUtterance</code> passed to <a data-custom-type=\"speech\" data-method=\"createRecognizeStream\">speech#createRecognizeStream</a> is <code>true</code>. It indicates that the server has detected the end of the user&#39;s speech utterance and expects no additional speech. Therefore, the server will not process additional audio. The client should stop sending additional audio data.</li> </ul> ","source":"packages/speech/src/index.js#L110","resources":[],"examples":[],"params":[],"exceptions":[],"returns":[]},{"id":"createRecognizeStream","name":"createRecognizeStream","type":"instance","description":"<p>Perform bidirectional streaming speech-recognition: receive results while sending audio.</p><p>Each emitted <code>data</code> event is a <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#streamingrecognizeresponse\"><code>StreamingRecognizeResponse</code></a> object, containing these properties:</p><ul> <li><strong><code>eventType</code></strong> See <a data-custom-type=\"speech\" data-method=\"eventTypes\">speech#eventTypes</a>.</li> <li><strong><code>results</code></strong> By default, a combined string of transcripts. When <code>config.verbose</code> is enabled, this is an object including a <code>transcript</code> property, a <code>confidence</code> score from <code>0</code> - <code>100</code>, and an <code>alternatives</code> array consisting of other transcription possibilities.</li> </ul> <p>Cloud Speech sets the limits for the audio duration. For more information, see <a href=\"<a href=\"https://cloud.google.com/speech/limits#content\">Content Limits</a>\">https://cloud.google.com/speech/limits#content}</a>.</p>","source":"packages/speech/src/index.js#L439","resources":[{"title":"StreamingRecognize API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.Speech.StreamingRecognize"},{"title":"StreamingRecognizeRequest API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.StreamingRecognizeRequest"},{"title":"Content Limits","link":"https://cloud.google.com/speech/limits#content"}],"examples":[{"code":"var fs = require('fs');"},{"caption":"<p>See <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.StreamingRecognizeRequest\"> \n<code>StreamingRecognizeRequest</code></a> for all of the available configuration \noptions.</p>","code":"var request = {\n  config: {\n    encoding: 'LINEAR16',\n    languageCode: 'en-US',\n    sampleRateHertz: 16000\n  },\n  singleUtterance: false,\n  interimResults: false\n};\n\nfs.createReadStream('./bridge.raw')\n  .on('error', console.error)\n  .pipe(speech.createRecognizeStream(request))\n  .on('error', console.error)\n  .on('data', function(data) {\n    // data.results = \"how old is the Brooklyn Bridge\"\n  });"},{"caption":"<p>Enable verbose mode for more detailed results.</p>","code":"var request = {\n  config: {\n    encoding: 'LINEAR16',\n    languageCode: 'en-US',\n    sampleRateHertz: 16000\n  },\n  singleUtterance: false,\n  interimResults: false,\n  verbose: true\n};\n\nfs.createReadStream('./system-test/data/bridge.raw')\n  .on('error', console.error)\n  .pipe(speech.createRecognizeStream(request))\n  .on('error', console.error)\n  .on('data', function(data) {\n    // data.results = \"how old is the Brooklyn Bridge\"\n  });"}],"params":[{"name":"config","description":"<ul> <li>A <code>StreamingRecognitionConfig</code> object. See <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.StreamingRecognitionConfig\"><code>StreamingRecognitionConfig</code></a>.</li> </ul> ","types":["object"],"optional":false,"nullable":false},{"name":"config.languageCode","description":"<ul> <li>The language of the supplied audio as <a href=\"http://bit.ly/1ZHeENX\">BCP-47 language tag</a>. Example: &#39;en-US&#39;.</li> </ul> ","types":["string"],"optional":false,"nullable":false},{"name":"config.timeout","description":"<ul> <li>In seconds, the amount of time before the underlying API request times out. The default value, <code>190</code>, is sufficient  for audio input of 60 seconds or less. If your input is longer, consider  using a higher timeout value.</li> </ul> ","types":["number"],"optional":true,"nullable":false},{"name":"config.verbose","description":"<ul> <li>Enable verbose mode for a more detailed response. See the examples below. Default: <code>false</code>.</li> </ul> ","types":["boolean"],"optional":true,"nullable":false}],"exceptions":[],"returns":[]},{"id":"operation","name":"operation","type":"instance","description":"<p>Get a reference to an existing operation.</p>","source":"packages/speech/src/index.js#L523","resources":[],"examples":[{"code":"var operation = speech.operation('68850831366825');"}],"params":[{"name":"name","description":"<ul> <li>The name of the operation.</li> </ul> ","types":["string"],"optional":false,"nullable":false}],"exceptions":[{"type":"Error","description":"<p>If a name is not provided.</p>"}],"returns":[]},{"id":"recognize","name":"recognize","type":"instance","description":"<p>Perform synchronous speech recognition and receive results after all audio has been sent and processed. This is ideal for files 1 MB or below. For larger files, you will need to use <a data-custom-type=\"speech\" data-method=\"startRecognition\">speech#startRecognition</a> or <a data-custom-type=\"speech\" data-method=\"createRecognizeStream\">speech#createRecognizeStream</a>.</p>","source":"packages/speech/src/index.js#L640","resources":[{"title":"Recognize API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.Speech.Recognize"},{"title":"RecognizeRequest API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.RecognizeRequest"}],"examples":[{"code":"var config = {\n  encoding: 'LINEAR16',\n  languageCode: 'en-US',\n  sampleRateHertz: 16000\n};\n\nfunction callback(err, transcript, apiResponse) {\n  if (err) {\n    // Error handling omitted.\n  }\n\n  // transcript = \"how old is the Brooklyn Bridge\"\n}"},{"caption":"<p>Run speech detection over a local file.</p>","code":"speech.recognize('./bridge.raw', config, callback);"},{"caption":"<p>Run speech recognition over a file in Cloud Storage.</p>","code":"speech.recognize('gs://your-bucket-name/bridge.raw', config, callback);"},{"caption":"<p>Run speech recognition over raw file contents.</p>","code":"speech.recognize({\n  content: fs.readFileSync('./bridge.raw')\n}, config, callback);"},{"caption":"<p>Run speech recognition over a remote file. \n<em>Note: This is not an officially supported feature of the Speech API. \nThis library will make a request to the URL given and send the file \ncontents to the upstream API.</em></p>","code":"speech.recognize('https://example.com/files/bridge.raw', config, callback);"},{"caption":"<p>Enable verbose mode for more detailed results.</p>","code":"var config = {\n  encoding: 'LINEAR16',\n  languageCode: 'en-US',\n  sampleRateHertz: 16000,\n  verbose: true\n};\n\nspeech.recognize('./bridge.raw', config, function(err, results) {\n  if (err) {\n    // Error handling omitted.\n  }\n\n  // results = [\n  //   {\n  //     transcript: \"how old is the Brooklyn Bridge\",\n  //     confidence: 88.15,\n  //     alternatives: [\n  //       {\n  //         transcript: \"how old is the Brooklyn brim\",\n  //         confidence: 22.39\n  //       }\n  //     ]\n  //   }\n  // ]\n});"},{"caption":"<p>If the callback is omitted, we'll return a Promise.</p>","code":"speech.recognize('./bridge.raw', config).then(function(data) {\n  var results = data[0];\n  var apiResponse = data[1];\n});"}],"params":[{"name":"file","description":"<ul> <li>The source file to run the detection on. It can be either a local file path, a remote file URL, a  Cloud Storage URI, a Cloud Storage File object, or a  <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.RecognitionAudio\"><code>RecognitionAudio</code></a>  object.</li> </ul> ","types":["string","object","<a data-custom-type=\"storage/file\" data-method=\"\">storage/file</a>"],"optional":false,"nullable":false},{"name":"config","description":"<ul> <li>A <code>RecognitionConfig</code> object. See <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.RecognitionConfig\"><code>RecognitionConfig</code></a>.</li> </ul> ","types":["object"],"optional":false,"nullable":false},{"name":"config.languageCode","description":"<ul> <li>The language of the supplied audio as <a href=\"http://bit.ly/1ZHeENX\">BCP-47 language tag</a>. Example: &#39;en-US&#39;.</li> </ul> ","types":["string"],"optional":false,"nullable":false},{"name":"config.verbose","description":"<ul> <li>Enable verbose mode for a more detailed response. See the examples below. Default: <code>false</code>.</li> </ul> ","types":["boolean"],"optional":true,"nullable":false},{"name":"callback","description":"<ul> <li>The callback function.</li> </ul> ","types":["function"],"optional":false,"nullable":false},{"name":"callback.err","description":"<ul> <li>An error returned while making this request.</li> </ul> ","types":["error"],"optional":false,"nullable":true},{"name":"callback.results","description":"<ul> <li>By default, this will be a string comprised of all of the transcriptions recognized from the audio. If  <code>config.verbose</code> is enabled, this is an object including a <code>transcript</code>  property, a <code>confidence</code> score from <code>0</code> - <code>100</code>, and an <code>alternatives</code>  array consisting of other transcription possibilities. See the examples  below for more.</li> </ul> ","types":["string","object[]"],"optional":false,"nullable":false},{"name":"callback.apiResponse","description":"<ul> <li>Raw API response. See <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#recognizeresponse\"><code>RecognizeResponse</code></a>.</li> </ul> ","types":["object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]},{"id":"startRecognition","name":"startRecognition","type":"instance","description":"<p>Perform asynchronous speech recognition.</p><p>This method sends audio to the Speech API, which immediately responds with an Operation object. Register event handlers for the &quot;error&quot; and &quot;complete&quot; events to see how the operation finishes. Follow along with the examples below.</p>","source":"packages/speech/src/index.js#L796","resources":[{"title":"LongRunningRecognize API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1.Speech.LongRunningRecognize"},{"title":"LongRunningRecognize API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1.LongRunningRecognizeRequest"},{"title":"LongRunningRecognize API Reference","link":"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1.LongRunningRecognizeResponse"}],"examples":[{"code":"var config = {\n  encoding: 'LINEAR16',\n  languageCode: 'en-US',\n  sampleRateHertz: 16000\n};\n\nfunction callback(err, operation, apiResponse) {\n  if (err) {\n    // Error handling omitted.\n  }\n\n  operation\n    .on('error', function(err) {})\n    .on('complete', function(transcript) {\n      // transcript = \"how old is the Brooklyn Bridge\"\n    });\n}"},{"caption":"<p>Run speech detection over a local file.</p>","code":"speech.startRecognition('./bridge.raw', config, callback);"},{"caption":"<p>Run speech detection over a file in Cloud Storage.</p>","code":"var file = 'gs://your-bucket-name/bridge.raw';\nspeech.startRecognition(file, config, callback);"},{"caption":"<p>Run speech detection over raw file contents.</p>","code":"speech.startRecognition({\n  content: fs.readFileSync('./bridge.raw')\n}, config, callback);"},{"caption":"<p>Run speech detection over a remote file. \n<em>Note: This is not an officially supported feature of the Speech API. \nThis library will make a request to the URL given and send the file \ncontents to the upstream API.</em></p>","code":"var file = 'https://example.com/files/bridge.raw';\n\nspeech.startRecognition(file, config, callback);"},{"caption":"<p>Enable verbose mode for more detailed results.</p>","code":"var config = {\n  encoding: 'LINEAR16',\n  languageCode: 'en-US',\n  sampleRateHertz: 16000,\n  verbose: true\n};\n\nspeech.startRecognition('./bridge.raw', config, function(err, operation) {\n  if (err) {\n    // Error handling omitted.\n  }\n\n  operation\n    .on('error', function(err) {})\n    .on('complete', function(results) {\n      // results = [\n      //   {\n      //     transcript: \"how old is the Brooklyn Bridge\",\n      //     confidence: 88.15\n      //   }\n      // ]\n    });\n});"},{"caption":"<p>If the callback is omitted, we'll return a Promise.</p>","code":"speech.startRecognition('./bridge.raw', config).then(function(data) {\n  var operation = data[0];\n  var apiResponse = data[1];\n});"}],"params":[{"name":"file","description":"<ul> <li>The source file to run the detection on. It can be either a local file path, a remote file URL, a  Cloud Storage URI, a Cloud Storage File object, or a  <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.RecognitionAudio\"><code>RecognitionAudio</code></a>  object.</li> </ul> ","types":["string","object","<a data-custom-type=\"storage/file\" data-method=\"\">storage/file</a>"],"optional":false,"nullable":false},{"name":"config","description":"<ul> <li>A <code>RecognitionConfig</code> object. See <a href=\"https://cloud.google.com/speech/reference/rpc/google.cloud.speech.v1beta1#google.cloud.speech.v1beta1.RecognitionConfig\"><code>RecognitionConfig</code></a>.</li> </ul> ","types":["object"],"optional":false,"nullable":false},{"name":"config.verbose","description":"<ul> <li>Enable verbose mode for a more detailed response. See the examples below. Default: <code>false</code>.</li> </ul> ","types":["boolean"],"optional":true,"nullable":false},{"name":"config.languageCode","description":"<ul> <li>The language of the supplied audio as <a href=\"http://bit.ly/1ZHeENX\">BCP-47 language tag</a>. Example: &#39;en-US&#39;.</li> </ul> ","types":["string"],"optional":false,"nullable":false},{"name":"callback","description":"<ul> <li>The callback function.</li> </ul> ","types":["function"],"optional":false,"nullable":false},{"name":"callback.err","description":"<ul> <li>An error returned while making this request.</li> </ul> ","types":["error"],"optional":false,"nullable":true},{"name":"callback.operation","description":"<ul> <li>An operation object that can be used to check the status of the request.</li> </ul> ","types":["<a data-custom-type=\"speech/operation\" data-method=\"\">speech/operation</a>"],"optional":false,"nullable":false},{"name":"callback.apiResponse","description":"<ul> <li>Raw API response.</li> </ul> ","types":["object"],"optional":false,"nullable":false}],"exceptions":[],"returns":[]}],"path":"index.json"}