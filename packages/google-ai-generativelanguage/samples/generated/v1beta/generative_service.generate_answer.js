// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **



'use strict';

function main(model, contents, answerStyle) {
  // [START generativelanguage_v1beta_generated_GenerativeService_GenerateAnswer_async]
  /**
   * This snippet has been automatically generated and should be regarded as a code template only.
   * It will require modifications to work.
   * It may require correct/in-range values for request initialization.
   * TODO(developer): Uncomment these variables before running the sample.
   */
  /**
   *  Passages provided inline with the request.
   */
  // const inlinePassages = {}
  /**
   *  Content retrieved from resources created via the Semantic Retriever
   *  API.
   */
  // const semanticRetriever = {}
  /**
   *  Required. The name of the `Model` to use for generating the grounded
   *  response.
   *  Format: `model=models/{model}`.
   */
  // const model = 'abc123'
  /**
   *  Required. The content of the current conversation with the `Model`. For
   *  single-turn queries, this is a single question to answer. For multi-turn
   *  queries, this is a repeated field that contains conversation history and
   *  the last `Content` in the list containing the question.
   *  Note: `GenerateAnswer` only supports queries in English.
   */
  // const contents = [1,2,3,4]
  /**
   *  Required. Style in which answers should be returned.
   */
  // const answerStyle = {}
  /**
   *  Optional. A list of unique `SafetySetting` instances for blocking unsafe
   *  content.
   *  This will be enforced on the `GenerateAnswerRequest.contents` and
   *  `GenerateAnswerResponse.candidate`. There should not be more than one
   *  setting for each `SafetyCategory` type. The API will block any contents and
   *  responses that fail to meet the thresholds set by these settings. This list
   *  overrides the default settings for each `SafetyCategory` specified in the
   *  safety_settings. If there is no `SafetySetting` for a given
   *  `SafetyCategory` provided in the list, the API will use the default safety
   *  setting for that category. Harm categories HARM_CATEGORY_HATE_SPEECH,
   *  HARM_CATEGORY_SEXUALLY_EXPLICIT, HARM_CATEGORY_DANGEROUS_CONTENT,
   *  HARM_CATEGORY_HARASSMENT are supported.
   *  Refer to the
   *  guide (https://ai.google.dev/gemini-api/docs/safety-settings)
   *  for detailed information on available safety settings. Also refer to the
   *  Safety guidance (https://ai.google.dev/gemini-api/docs/safety-guidance) to
   *  learn how to incorporate safety considerations in your AI applications.
   */
  // const safetySettings = [1,2,3,4]
  /**
   *  Optional. Controls the randomness of the output.
   *  Values can range from 0.0,1.0, inclusive. A value closer to 1.0 will
   *  produce responses that are more varied and creative, while a value closer
   *  to 0.0 will typically result in more straightforward responses from the
   *  model. A low temperature (~0.2) is usually recommended for
   *  Attributed-Question-Answering use cases.
   */
  // const temperature = 1234

  // Imports the Generativelanguage library
  const {GenerativeServiceClient} = require('@google-ai/generativelanguage').v1beta;

  // Instantiates a client
  const generativelanguageClient = new GenerativeServiceClient();

  async function callGenerateAnswer() {
    // Construct request
    const request = {
      model,
      contents,
      answerStyle,
    };

    // Run request
    const response = await generativelanguageClient.generateAnswer(request);
    console.log(response);
  }

  callGenerateAnswer();
  // [END generativelanguage_v1beta_generated_GenerativeService_GenerateAnswer_async]
}

process.on('unhandledRejection', err => {
  console.error(err.message);
  process.exitCode = 1;
});
main(...process.argv.slice(2));
