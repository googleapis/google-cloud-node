// Copyright 2024 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
// ** This file is automatically generated by gapic-generator-typescript. **
// ** https://github.com/googleapis/gapic-generator-typescript **
// ** All changes to this file may be overwritten. **



'use strict';

function main(endpoint) {
  // [START aiplatform_v1_generated_LlmUtilityService_CountTokens_async]
  /**
   * This snippet has been automatically generated and should be regarded as a code template only.
   * It will require modifications to work.
   * It may require correct/in-range values for request initialization.
   * TODO(developer): Uncomment these variables before running the sample.
   */
  /**
   *  Required. The name of the Endpoint requested to perform token counting.
   *  Format:
   *  `projects/{project}/locations/{location}/endpoints/{endpoint}`
   */
  // const endpoint = 'abc123'
  /**
   *  Optional. The name of the publisher model requested to serve the
   *  prediction. Format:
   *  `projects/{project}/locations/{location}/publishers/* /models/*`
   */
  // const model = 'abc123'
  /**
   *  Optional. The instances that are the input to token counting call.
   *  Schema is identical to the prediction schema of the underlying model.
   */
  // const instances = [1,2,3,4]
  /**
   *  Optional. Input content.
   */
  // const contents = [1,2,3,4]
  /**
   *  Optional. The user provided system instructions for the model.
   *  Note: only text should be used in parts and content in each part will be in
   *  a separate paragraph.
   */
  // const systemInstruction = {}
  /**
   *  Optional. A list of `Tools` the model may use to generate the next
   *  response.
   *  A `Tool` is a piece of code that enables the system to interact with
   *  external systems to perform an action, or set of actions, outside of
   *  knowledge and scope of the model.
   */
  // const tools = [1,2,3,4]

  // Imports the Aiplatform library
  const {LlmUtilityServiceClient} = require('@google-cloud/aiplatform').v1;

  // Instantiates a client
  const aiplatformClient = new LlmUtilityServiceClient();

  async function callCountTokens() {
    // Construct request
    const request = {
      endpoint,
    };

    // Run request
    const response = await aiplatformClient.countTokens(request);
    console.log(response);
  }

  callCountTokens();
  // [END aiplatform_v1_generated_LlmUtilityService_CountTokens_async]
}

process.on('unhandledRejection', err => {
  console.error(err.message);
  process.exitCode = 1;
});
main(...process.argv.slice(2));
